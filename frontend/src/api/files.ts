import { supabase } from '../supabaseClient'
import { validateAuth, handleAPIError } from '../utils/authHelpers'
import { getCategoryFromPageKey } from './entries'
import { getCategoryInfo } from '../utils/categoryConstants'


export interface FileMetadata {
  pageKey: string
  standard: string  // ISO æ¨™æº–ä»£ç¢¼ï¼š'64' (ISO 14064) æˆ– '67' (ISO 14067)
  year?: number  // æœŸé–“å¹´ä»½ï¼Œé è¨­ç‚ºç•¶å‰å¹´ä»½
  month?: number  // åƒ…ç”¨æ–¼ usage_evidenceï¼Œè¡¨ç¤ºæœˆä»½ (1-12)
  recordIndex?: number  // ç”¨æ–¼å¤šç­†è¨˜éŒ„é é¢ï¼ˆå¦‚æŸ´æ²¹ï¼‰ï¼Œè¡¨ç¤ºè¨˜éŒ„ç´¢å¼• (0, 1, 2...) - èˆŠåšæ³•
  recordId?: string  // ç”¨æ–¼å¤šç­†è¨˜éŒ„é é¢ï¼Œç©©å®šçš„è¨˜éŒ„ IDï¼ˆå¦‚ "fire_extinguisher_123"ï¼‰- æ–°åšæ³•
  allRecordIds?: string[]  // â­ ç¾¤çµ„çš„æ‰€æœ‰ recordIdï¼ˆç”¨æ–¼ N:1 å…±äº«ä½è­‰ï¼‰
  fileType?: 'msds' | 'usage_evidence' | 'other' | 'heat_value_evidence' | 'annual_evidence' | 'nameplate_evidence' | 'sf6_nameplate' | 'sf6_certificate'  // â­ æ–°å¢ SF6 æª”æ¡ˆé¡å‹
  category?: 'msds' | 'usage_evidence' | 'other' | 'heat_value_evidence' | 'annual_evidence' | 'nameplate_evidence' | 'sf6_nameplate' | 'sf6_certificate'  // å‘å¾Œç›¸å®¹ï¼ˆå·²å»¢æ£„ï¼‰
}

export interface UploadOptions {
  allowOverwrite?: boolean
}

export interface EvidenceFile {
  id: string
  owner_id: string
  entry_id: string
  file_path: string
  file_name: string
  mime_type: string
  file_size: number
  created_at: string
  month?: number | null  // æœˆä»½æ¬„ä½ï¼ŒNULL è¡¨ç¤º MSDS
  page_key?: string      // é é¢æ¨™è­˜ç¬¦
  record_index?: number | null  // è¨˜éŒ„ç´¢å¼•ï¼ˆç”¨æ–¼å¤šç­†è¨˜éŒ„é é¢ï¼‰- èˆŠåšæ³•
  record_id?: string | null  // è¨˜éŒ„ IDï¼ˆç©©å®š IDï¼‰- èˆŠåšæ³•
  record_ids?: string[] | null  // è¨˜éŒ„ IDsï¼ˆå¤šå°ä¸€é—œä¿‚ï¼‰- æ–°åšæ³•
  file_type: 'msds' | 'usage_evidence' | 'other' | 'heat_value_evidence' | 'annual_evidence' | 'nameplate_evidence' | 'sf6_nameplate' | 'sf6_certificate'  // æª”æ¡ˆé¡å‹æ¬„ä½ (å¿…å¡«)
  // Join fields from energy_entries
  status?: 'saved' | 'submitted' | 'approved' | 'rejected'  // From energy_entries
  period_year?: number  // From energy_entries
}

/**
 * æ¨æ–·æª”æ¡ˆ MIME é¡å‹
 */
function inferMimeType(file: File): string {
  // å„ªå…ˆä½¿ç”¨ file.typeï¼ˆæ’é™¤é€šç”¨å‹ï¼‰
  if (file.type && file.type !== 'application/octet-stream') {
    return file.type
  }

  // å¦‚æœ file.type ç‚ºç©ºæˆ–æ˜¯é€šç”¨å‹ï¼Œå˜—è©¦å¾å‰¯æª”åæ¨æ–·
  const extension = file.name.split('.').pop()?.toLowerCase()

  switch (extension) {
    case 'jpg':
    case 'jpeg':
      return 'image/jpeg'
    case 'png':
      return 'image/png'
    case 'gif':
      return 'image/gif'
    case 'webp':
      return 'image/webp'
    case 'heic':
      return 'image/heic'
    case 'heif':
      return 'image/heif'
    case 'pdf':
      return 'application/pdf'
    case 'xlsx':
      return 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    case 'xls':
      return 'application/vnd.ms-excel'
    case 'docx':
      return 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
    case 'doc':
      return 'application/msword'
    default:
      return 'application/octet-stream'
  }
}

/**
 * é©—è­‰æª”æ¡ˆé¡å‹ï¼ˆå·²ç§»é™¤é™åˆ¶ï¼Œå…è¨±æ‰€æœ‰é¡å‹ï¼‰
 */
function validateFileType(file: File): { valid: boolean; error?: string } {
  // ç§»é™¤æª”æ¡ˆé¡å‹é™åˆ¶ï¼Œå…è¨±æ‰€æœ‰æª”æ¡ˆä¸Šå‚³
  return { valid: true }
}

/**
 * ä¸Šå‚³è­‰æ“šæª”æ¡ˆåˆ° Storage ä¸¦å»ºç«‹è¨˜éŒ„ï¼ˆæ”¯æ´æª”æ¡ˆè¦†è“‹ï¼‰
 * æ³¨æ„ï¼šæª”æ¡ˆæœƒè‡ªå‹•é—œè¯åˆ°å°æ‡‰çš„ energy_entries è¨˜éŒ„
 * å¦‚æœè©²ç”¨æˆ¶çš„è©²é é¢é‚„æ²’æœ‰ entry è¨˜éŒ„ï¼Œæœƒè‡ªå‹•å»ºç«‹ä¸€å€‹è‰ç¨¿è¨˜éŒ„
 */
export async function uploadEvidence(file: File, meta: FileMetadata & { entryId?: string; allowOverwrite?: boolean }): Promise<EvidenceFile> {
  return await uploadEvidenceWithValidation(file, meta, true)
}

/**
 * ä¸Šå‚³è­‰æ“šæª”æ¡ˆä¸¦é©—è­‰å¿…é ˆæœ‰ entry_id
 * @param file - è¦ä¸Šå‚³çš„æª”æ¡ˆ
 * @param meta - æª”æ¡ˆå…ƒæ•¸æ“šï¼Œå¿…é ˆåŒ…å« entryId
 * @returns Promise<EvidenceFile>
 */
export async function uploadEvidenceWithEntry(file: File, meta: FileMetadata & { entryId: string; allowOverwrite?: boolean }): Promise<EvidenceFile> {
  return await uploadEvidenceWithValidation(file, meta, false)
}

/**
 * å…§éƒ¨å‡½æ•¸ï¼šä¸Šå‚³è­‰æ“šæª”æ¡ˆçš„æ ¸å¿ƒé‚è¼¯
 * @param file - è¦ä¸Šå‚³çš„æª”æ¡ˆ
 * @param meta - æª”æ¡ˆå…ƒæ•¸æ“š
 * @param allowAutoCreateEntry - æ˜¯å¦å…è¨±è‡ªå‹•å»ºç«‹ energy_entry
 */
async function uploadEvidenceWithValidation(file: File, meta: FileMetadata & { entryId?: string; allowOverwrite?: boolean }, allowAutoCreateEntry: boolean): Promise<EvidenceFile> {
  console.log('ğŸ” [DEBUG] uploadEvidenceWithValidation called:', {
    fileName: file.name,
    fileSize: file.size,
    meta,
    allowAutoCreateEntry
  })

  try {
    const authResult = await validateAuth()
    console.log('ğŸ” [DEBUG] Auth validation result:', {
      hasError: !!authResult.error,
      hasUser: !!authResult.user,
      userId: authResult.user?.id,
      errorMessage: authResult.error?.message
    })

    if (authResult.error || !authResult.user) {
      console.error('âŒ [DEBUG] Auth validation failed:', authResult.error)
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    const user = authResult.user

    // ç¢ºä¿ year æœ‰å€¼ï¼Œé è¨­ç‚ºç•¶å‰å¹´ä»½
    const currentYear = meta.year || new Date().getFullYear()

    // é©—è­‰æª”æ¡ˆé¡å‹
    const typeValidation = validateFileType(file)
    if (!typeValidation.valid) {
      throw new Error(typeValidation.error!)
    }

    // æ¨æ–·æ­£ç¢ºçš„ MIME é¡å‹
    const resolvedType = inferMimeType(file)

    // Month å’Œ file_type åƒæ•¸é©—è­‰ï¼ˆå„ªå…ˆä½¿ç”¨ meta.fileTypeï¼‰
    const expectedFileType = meta.fileType || (meta.category === 'msds' ? 'msds' :
                            meta.category === 'usage_evidence' ? 'usage_evidence' :
                            meta.category === 'annual_evidence' ? 'annual_evidence' :
                            meta.category === 'nameplate_evidence' ? 'nameplate_evidence' : 'other')

    console.log('ğŸ” [uploadEvidence] File type validation:', {
      file_name: file.name,
      fileType: meta.fileType,
      category: meta.category,
      month_input: meta.month,
      expected_file_type: expectedFileType
    })

    // è¨˜éŒ„ä¸Šå‚³åƒæ•¸ï¼ˆä¸åšé™åˆ¶ï¼‰
    console.log('ğŸ“ [uploadEvidence] File upload info:', {
      file_name: file.name,
      category: meta.category || 'not specified',
      month: meta.month || 'not specified',
      page_key: meta.pageKey
    })

    // åªæœ‰ç•¶ allowOverwrite ç‚º true æ™‚æ‰åˆªé™¤ç¾æœ‰æª”æ¡ˆ
    if (meta.allowOverwrite) {
      // æª¢æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒæ¢ä»¶çš„æª”æ¡ˆï¼ˆåŒä¸€ä½¿ç”¨è€…ã€é é¢ã€å¹´ä»½ï¼‰
      let existingFileQuery = supabase
        .from('entry_files')
        .select(`
          *,
          energy_entries!inner(page_key, owner_id, period_year, status)
        `)
        .eq('owner_id', user.id)
        .eq('energy_entries.page_key', meta.pageKey)
        .eq('energy_entries.owner_id', user.id)
        .eq('energy_entries.period_year', meta.year)
        .eq('energy_entries.status', 'submitted')

      const { data: existingFiles, error: queryError } = await existingFileQuery

      if (queryError) {
        console.error('Error querying existing files:', queryError)
        throw handleAPIError(queryError, 'æŸ¥è©¢ç¾æœ‰æª”æ¡ˆå¤±æ•—')
      }

      // å¦‚æœæœ‰ç¾æœ‰æª”æ¡ˆä¸”å…è¨±è¦†è“‹ï¼Œå…ˆåˆªé™¤èˆŠæª”æ¡ˆ
      if (existingFiles && existingFiles.length > 0) {
        for (const existingFile of existingFiles) {
          // å¾ Storage åˆªé™¤èˆŠæª”æ¡ˆ
          const { error: storageDeleteError } = await supabase.storage
            .from('evidence')
            .remove([existingFile.file_path])

          if (storageDeleteError) {
            console.warn('Warning: Failed to delete old file from storage:', storageDeleteError)
          }

          // å¾è³‡æ–™åº«åˆªé™¤èˆŠè¨˜éŒ„
          const { error: dbDeleteError } = await supabase
            .from('entry_files')
            .delete()
            .eq('id', existingFile.id)

          if (dbDeleteError) {
            console.warn('Warning: Failed to delete old file record:', dbDeleteError)
          }
        }
      }
    }

    // å®‰å…¨è™•ç†æª”æ¡ˆåç¨±ï¼ˆä½¿ç”¨å­—ç¬¦æ›¿æ›ç¢ºä¿ Supabase Storage å…¼å®¹æ€§ï¼‰
    console.log('ğŸ”§ [DEBUG] è™•ç†æª”æ¡ˆåç¨±:', {
      åŸå§‹æª”å: file.name,
      æª”æ¡ˆå¤§å°: file.size,
      æª”æ¡ˆé¡å‹: file.type
    })

    const safeName = file.name
      .normalize('NFKD')                    // æ¨™æº–åŒ– Unicode å­—ç¬¦
      .replace(/[^\x00-\x7F]/g, '')         // ç§»é™¤æ‰€æœ‰é ASCII å­—ç¬¦
      .replace(/[\/\\:*?"<>|\s]+/g, '_')    // æ›¿æ›ç‰¹æ®Šå­—ç¬¦å’Œç©ºæ ¼
      .replace(/_{2,}/g, '_')               // å°‡å¤šå€‹é€£çºŒåº•ç·šåˆä½µç‚ºä¸€å€‹
      .replace(/^_+|_+$/g, '')              // ç§»é™¤é–‹é ­å’Œçµå°¾çš„åº•ç·š
      .substring(0, 50) || 'file';          // é™åˆ¶é•·åº¦ï¼Œå¦‚æœç‚ºç©ºå‰‡ä½¿ç”¨é è¨­åç¨±

    console.log('âœ… [DEBUG] æª”æ¡ˆåç¨±è™•ç†å®Œæˆ:', {
      åŸå§‹æª”å: file.name,
      å®‰å…¨æª”å: safeName,
      è™•ç†æ­¥é©Ÿ: 'æ¨™æº–åŒ– -> ç§»é™¤éASCII -> æ›¿æ›ç‰¹æ®Šå­—ç¬¦ -> é™åˆ¶é•·åº¦'
    })
    
    const timestamp = Date.now()
    const randomSuffix = Math.random().toString(36).substring(2, 8) // æ–°å¢éš¨æ©Ÿå­—ä¸²ä»¥é˜²æ­¢è¡çª
    
    // ä½¿ç”¨æ™‚é–“æˆ³ + éš¨æ©Ÿå­—ä¸²ç¢ºä¿æª”æ¡ˆåç¨±å”¯ä¸€æ€§
    const fileName = `${timestamp}_${randomSuffix}_${safeName}`
    
    console.log('ğŸ” [DEBUG] Building file path:', {
      userId: user.id,
      pageKey: meta.pageKey,
      year: meta.year,
      category: meta.category,
      month: meta.month,
      fileName: fileName,
      safeName: safeName
    })

    // æ§‹é€ æª”æ¡ˆè·¯å¾‘ï¼š{userId}/{standard}/{pageKey}/{month?}/{filename}
    const monthPath = meta.month ? `/${meta.month}` : ''
    const filePath = `${user.id}/${meta.standard}/${meta.pageKey}${monthPath}/${fileName}`

    console.log('ğŸ” [DEBUG] Constructed file path:', {
      monthPath,
      fullFilePath: filePath
    })

    // é©—è­‰æª”æ¡ˆè·¯å¾‘æ ¼å¼
    if (filePath.includes('//') || filePath.includes('..') || filePath.length > 1024) {
      throw new Error('æª”æ¡ˆè·¯å¾‘æ ¼å¼ç„¡æ•ˆ')
    }


    // ä¸Šå‚³æª”æ¡ˆåˆ° Storage
    console.log('ğŸ” [DEBUG] Starting storage upload:', {
      bucket: 'evidence',
      filePath,
      fileSize: file.size,
      contentType: resolvedType,
      supabaseUrl: (supabase as any)?.supabaseUrl || 'unknown',
      hasStorageClient: !!supabase.storage
    })

    const { data: uploadData, error: uploadError } = await supabase.storage
      .from('evidence')
      .upload(filePath, file, {
        upsert: true,
        contentType: resolvedType
      })

    if (uploadError) {
      console.error('âŒ [DEBUG] Storage upload failed:', {
        error: uploadError,
        errorMessage: uploadError.message,
        errorCode: (uploadError as any)?.code,
        statusCode: (uploadError as any)?.statusCode,
        filePath,
        fileSize: file.size
      })

      // ç‰¹æ®ŠéŒ¯èª¤è™•ç†
      if (uploadError.message.includes('Bucket not found')) {
        console.error('âŒ [DEBUG] Bucket not found error - evidence bucket does not exist')
        throw new Error('è«‹å…ˆå»ºç«‹ evidence bucket ä¸¦ç¢ºèªåç¨±')
      }

      if (uploadError.message.includes('Permission denied') || (uploadError as any)?.statusCode === 401) {
        console.error('âŒ [DEBUG] Permission denied - authentication or RLS issue')
      }

      throw handleAPIError(uploadError, 'æª”æ¡ˆä¸Šå‚³å¤±æ•—')
    }

    console.log('âœ… [DEBUG] Storage upload successful:', {
      uploadPath: uploadData?.path,
      uploadId: uploadData?.id
    })

    // é©—è­‰ entry_id æ˜¯å¦å­˜åœ¨ï¼ˆå¿…é ˆé—œè¯åˆ°ç¾æœ‰çš„ energy_entries è¨˜éŒ„ï¼‰
    if (!meta.entryId) {
      if (!allowAutoCreateEntry) {
        throw new Error('æª”æ¡ˆä¸Šå‚³å¿…é ˆé—œè¯åˆ°ç¾æœ‰çš„èƒ½æºè¨˜éŒ„')
      }
      
      // å˜—è©¦å°‹æ‰¾ç¾æœ‰çš„å·²æäº¤è¨˜éŒ„
      // æ ¹æ“šè³‡æ–™åº«å”¯ä¸€ç´„æŸï¼Œä½¿ç”¨ category è€Œä¸æ˜¯ page_key æŸ¥è©¢
      const categoryInfo = getCategoryInfo(meta.pageKey)
      const { data: existingEntry } = await supabase
        .from('energy_entries')
        .select('id')
        .eq('owner_id', user.id)
        .eq('category', categoryInfo.category)
        .eq('period_year', meta.year)
        .eq('status', 'submitted')
        .maybeSingle()
      
      if (!existingEntry) {
        console.log('ğŸ” [uploadEvidenceWithValidation] æ²’æœ‰æ‰¾åˆ°è¨˜éŒ„ï¼Œæº–å‚™å»ºç«‹æ–°è¨˜éŒ„')
        console.log('ğŸ” [uploadEvidenceWithValidation] pageKey:', meta.pageKey)

        // ç²å–å®Œæ•´çš„ category è³‡è¨Šï¼ŒåŒ…å« scope
        const categoryInfo = getCategoryInfo(meta.pageKey)
        console.log('ğŸ” [uploadEvidenceWithValidation] categoryInfo:', categoryInfo)

        // å¦‚æœæ²’æœ‰è‰ç¨¿è¨˜éŒ„ï¼Œå˜—è©¦å»ºç«‹æˆ–æ›´æ–°ä¸€å€‹
        // ä½¿ç”¨ upsert é¿å…é‡è¤‡æ’å…¥éŒ¯èª¤
        const { data: upsertResult, error: entryError } = await supabase
          .from('energy_entries')
          .upsert({
            owner_id: user.id,
            page_key: meta.pageKey,
            period_year: meta.year,
            category: categoryInfo.category,
            scope: categoryInfo.scope,
            unit: categoryInfo.unit,
            amount: 0.00001, // é è¨­ç‚ºæœ€å°å€¼é¿å… amount > 0 ç´„æŸéŒ¯èª¤
            status: 'submitted',
            period_start: `${meta.year}-01-01`,
            period_end: `${meta.year}-12-31`,
            payload: {}
          }, { 
            onConflict: 'owner_id,category,period_year',  // æ ¹æ“šè³‡æ–™åº«å”¯ä¸€ç´„æŸé€²è¡Œè¡çªè™•ç†
            ignoreDuplicates: false  // ä¸å¿½ç•¥é‡è¤‡ï¼Œè€Œæ˜¯æ›´æ–°
          })
          .select('id')
          .maybeSingle()  // ä½¿ç”¨ maybeSingle é¿å… single() çš„éŒ¯èª¤
        
        if (entryError) {
          throw new Error(`ç„¡æ³•å»ºç«‹èƒ½æºè¨˜éŒ„: ${entryError.message}`)
        }
        
        // å¦‚æœ upsert æˆåŠŸä½†æ²’æœ‰è¿”å›è³‡æ–™ï¼Œå†æŸ¥è©¢ä¸€æ¬¡
        if (!upsertResult) {
          // ç­‰å¾…ä¸€å°æ®µæ™‚é–“ç¢ºä¿è³‡æ–™åº«æ“ä½œå®Œæˆ
          await new Promise(resolve => setTimeout(resolve, 100))
          
          const { data: existingAfterUpsert, error: queryError } = await supabase
            .from('energy_entries')
            .select('id')
            .eq('owner_id', user.id)
            .eq('category', categoryInfo.category)
            .eq('period_year', meta.year)
            .eq('status', 'submitted')
            .maybeSingle()
          
          if (queryError) {
            console.error('Query error after upsert:', queryError)
            throw new Error(`æŸ¥è©¢èƒ½æºè¨˜éŒ„å¤±æ•—: ${queryError.message}`)
          }
          
          if (!existingAfterUpsert) {
            // å˜—è©¦æŸ¥è©¢æ‰€æœ‰ç‹€æ…‹çš„è¨˜éŒ„ï¼Œçœ‹çœ‹æ˜¯å¦å­˜åœ¨ä½†ç‹€æ…‹ä¸åŒ
            const { data: anyStatusRecord, error: anyStatusError } = await supabase
              .from('energy_entries')
              .select('id, status')
              .eq('owner_id', user.id)
              .eq('category', categoryInfo.category)
              .eq('period_year', meta.year)
              .maybeSingle()
            
            if (anyStatusError) {
              console.error('Any status query error:', anyStatusError)
            }
            
            if (anyStatusRecord) {
              meta.entryId = anyStatusRecord.id
            } else {
              console.error('No record found after upsert. Debug info:', {
                user_id: user.id,
                category: categoryInfo.category,
                period_year: meta.year,
                page_key: meta.pageKey
              })
              throw new Error('å»ºç«‹èƒ½æºè¨˜éŒ„å¾Œç„¡æ³•æ‰¾åˆ°è©²è¨˜éŒ„')
            }
          } else {
            meta.entryId = existingAfterUpsert.id
          }
        } else {
          meta.entryId = upsertResult.id
        }
      } else {
        meta.entryId = existingEntry.id
      }
    }
    
    // æœ€çµ‚é©—è­‰ entry_id æ˜¯å¦å­˜åœ¨
    if (!meta.entryId) {
      throw new Error('ç„¡æ³•å–å¾—æœ‰æ•ˆçš„èƒ½æºè¨˜éŒ„ ID')
    }

    // å»ºç«‹è³‡æ–™åº«è¨˜éŒ„ï¼ˆå„ªå…ˆä½¿ç”¨ meta.fileTypeï¼‰
    const monthValue = expectedFileType === 'usage_evidence' ? meta.month : null
    const fileTypeValue = meta.fileType || (meta.category === 'msds' ? 'msds' :
                         meta.category === 'usage_evidence' ? 'usage_evidence' :
                         meta.category === 'annual_evidence' ? 'annual_evidence' :
                         meta.category === 'nameplate_evidence' ? 'nameplate_evidence' : 'other')

    const fileRecord = {
      owner_id: user.id,
      entry_id: meta.entryId, // ç¾åœ¨ä¿è­‰æœ‰å€¼
      file_path: uploadData.path,
      file_name: file.name,
      mime_type: resolvedType,
      file_size: file.size,
      page_key: meta.pageKey,
      month: monthValue,
      file_type: fileTypeValue,
      record_index: meta.recordIndex ?? null,  // èˆŠåšæ³•ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
      record_id: meta.recordId ?? null,  // èˆŠåšæ³•ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
      record_ids: meta.allRecordIds || (meta.recordId ? [meta.recordId] : null)  // â­ å„ªå…ˆä½¿ç”¨ allRecordIds
    }

    console.log('ğŸ’¾ [uploadEvidence] Database record:', {
      file_name: file.name,
      file_name_type: typeof file.name,
      file_name_length: file.name?.length,
      file_name_undefined: file.name === undefined,
      file_name_null: file.name === null,
      file_name_empty: file.name === '',
      fileType_input: meta.fileType,
      category: meta.category,
      month_input: meta.month,
      final_month_value: monthValue,
      final_file_type: fileTypeValue,
      page_key: meta.pageKey,
      entry_id: meta.entryId
    })

    const { data: dbData, error: dbError } = await supabase
      .from('entry_files')
      .insert(fileRecord)
      .select()
      .single()

    if (dbError) {
      // å¦‚æœè³‡æ–™åº«æ’å…¥å¤±æ•—ï¼Œæ¸…ç†å·²ä¸Šå‚³çš„æª”æ¡ˆ
      await supabase.storage.from('evidence').remove([uploadData.path])
      console.error('Error creating file record:', dbError)
      throw handleAPIError(dbError, `å»ºç«‹æª”æ¡ˆè¨˜éŒ„å¤±æ•—: ${dbError.message}`)
    }

    // â­ é©—è­‰è³‡æ–™åº«å¯¦éš›å„²å­˜çš„è³‡æ–™
    console.log('âœ… [uploadEvidence] Database record saved:', {
      id: dbData.id,
      file_name: dbData.file_name,
      file_name_is_undefined: dbData.file_name === undefined,
      file_path: dbData.file_path,
      record_id: dbData.record_id,
      record_ids: dbData.record_ids
    })

    return dbData
  } catch (error) {
    console.error('Error in uploadEvidenceWithValidation:', error)
    if (error instanceof Error) {
      throw error
    }
    throw new Error('ä¸Šå‚³æª”æ¡ˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

/**
 * å–å¾—æŒ‡å®šé é¢å’Œé¡åˆ¥çš„è‰ç¨¿æª”æ¡ˆæ¸…å–®
 */
export async function listEvidenceByCategory(
  pageKey: string,
  category: 'msds' | 'usage_evidence' | 'heat_value_evidence' | 'other',
  month?: number
): Promise<EvidenceFile[]> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    const user = authResult.user

    let query = supabase
      .from('entry_files')
      .select(`
        *,
        energy_entries!inner(page_key, status, period_year)
      `)
      .eq('owner_id', user.id)
      .eq('energy_entries.page_key', pageKey)
      .eq('energy_entries.owner_id', user.id)
      .in('energy_entries.status', ['submitted'])
      .order('created_at', { ascending: false })

    // æ ¹æ“šé¡åˆ¥å’Œæœˆä»½éæ¿¾æª”æ¡ˆè·¯å¾‘
    const yearStr = new Date().getFullYear().toString()
    let pathPattern = `${user.id}/${pageKey}/${yearStr}/${category}`
    
    if (category === 'usage_evidence' && month) {
      pathPattern += `/${month}`
    }
    
    // ä½¿ç”¨ LIKE æŸ¥è©¢åŒ¹é…è·¯å¾‘æ¨¡å¼
    query = query.like('file_path', `${pathPattern}%`)

    const { data, error } = await query

    if (error) {
      console.error('Error listing evidence by category:', error)
      throw handleAPIError(error, 'å–å¾—æª”æ¡ˆæ¸…å–®å¤±æ•—')
    }

    // Flatten the joined data
    const flattenedData = (data || []).map(item => ({
      ...item,
      page_key: item.energy_entries?.page_key,
      status: item.energy_entries?.status,
      period_year: item.energy_entries?.period_year,
      energy_entries: undefined // Remove nested object
    }))

    return flattenedData || []
  } catch (error) {
    console.error('Error in listEvidenceByCategory:', error)
    if (error instanceof Error) {
      throw error
    }
    throw new Error('å–å¾—æª”æ¡ˆæ¸…å–®æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

/**
 * å–å¾— MSDS æª”æ¡ˆæ¸…å–®
 */
export async function listMSDSFiles(pageKey: string, year?: number): Promise<EvidenceFile[]> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    const user = authResult.user

    const currentYear = year || new Date().getFullYear()

    console.log('ğŸ” [listMSDSFiles] Query params:', {
      pageKey,
      year: currentYear,
      user_id: user.id,
      file_type: 'msds'
    })

    const { data, error } = await supabase
      .from('entry_files')
      .select(`
        *,
        energy_entries!inner(page_key, status, period_year)
      `)
      .eq('owner_id', user.id)
      .eq('energy_entries.page_key', pageKey)
      .eq('energy_entries.owner_id', user.id)
      .eq('energy_entries.period_year', currentYear)
      .eq('file_type', 'msds')
      .order('created_at', { ascending: false })

    if (error) {
      console.error('Error listing MSDS files:', error)
      throw handleAPIError(error, 'å–å¾— MSDS æª”æ¡ˆæ¸…å–®å¤±æ•—')
    }

    const flattenedData = (data || []).map(item => ({
      ...item,
      page_key: item.energy_entries?.page_key,
      status: item.energy_entries?.status,
      period_year: item.energy_entries?.period_year,
      energy_entries: undefined
    }))

    // å»é‡è™•ç†
    const deduplicatedData = Array.from(
      new Map(flattenedData.map(file => [file.id, file])).values()
    )

    if (flattenedData.length !== deduplicatedData.length) {
      console.log('ğŸ”„ [listMSDSFiles] Deduplication:', {
        original_count: flattenedData.length,
        deduplicated_count: deduplicatedData.length,
        removed_duplicates: flattenedData.length - deduplicatedData.length
      })
    }

    console.log('âœ… [listMSDSFiles] Results:', {
      count: deduplicatedData.length,
      file_ids: deduplicatedData.map(f => f.id)
    })

    return deduplicatedData
  } catch (error) {
    console.error('Error in listMSDSFiles:', error)
    throw error instanceof Error ? error : new Error('å–å¾— MSDS æª”æ¡ˆæ¸…å–®æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

/**
 * å–å¾—æŒ‡å®šæœˆä»½çš„ä½¿ç”¨è­‰æ˜æª”æ¡ˆæ¸…å–®
 */
export async function listUsageEvidenceFiles(pageKey: string, month: number, year?: number): Promise<EvidenceFile[]> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    const user = authResult.user

    const currentYear = year || new Date().getFullYear()

    console.log('ğŸ” [listUsageEvidenceFiles] Query params:', {
      pageKey,
      month,
      year: currentYear,
      user_id: user.id,
      file_type: 'usage_evidence'
    })

    const { data, error } = await supabase
      .from('entry_files')
      .select(`
        *,
        energy_entries!inner(page_key, status, period_year)
      `)
      .eq('owner_id', user.id)
      .eq('energy_entries.page_key', pageKey)
      .eq('energy_entries.owner_id', user.id)
      .eq('energy_entries.period_year', currentYear)
      .eq('file_type', 'usage_evidence')
      .eq('month', month)
      .order('created_at', { ascending: false })

    if (error) {
      console.error('Error listing usage evidence files:', error)
      throw handleAPIError(error, 'å–å¾—ä½¿ç”¨è­‰æ˜æª”æ¡ˆæ¸…å–®å¤±æ•—')
    }

    const flattenedData = (data || []).map(item => ({
      ...item,
      page_key: item.energy_entries?.page_key,
      status: item.energy_entries?.status,
      period_year: item.energy_entries?.period_year,
      energy_entries: undefined
    }))

    // å»é‡è™•ç†
    const deduplicatedData = Array.from(
      new Map(flattenedData.map(file => [file.id, file])).values()
    )

    if (flattenedData.length !== deduplicatedData.length) {
      console.log('ğŸ”„ [listUsageEvidenceFiles] Deduplication:', {
        month,
        original_count: flattenedData.length,
        deduplicated_count: deduplicatedData.length,
        removed_duplicates: flattenedData.length - deduplicatedData.length
      })
    }

    console.log('âœ… [listUsageEvidenceFiles] Results:', {
      month,
      count: deduplicatedData.length,
      file_ids: deduplicatedData.map(f => f.id)
    })

    return deduplicatedData
  } catch (error) {
    console.error('Error in listUsageEvidenceFiles:', error)
    throw error instanceof Error ? error : new Error('å–å¾—ä½¿ç”¨è­‰æ˜æª”æ¡ˆæ¸…å–®æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

/**
 * å–å¾—æŒ‡å®šé é¢çš„æª”æ¡ˆæ¸…å–® (å‘å¾Œç›¸å®¹ï¼Œä½†å»ºè­°ä½¿ç”¨åˆ†é¡å‡½æ•¸)
 * @deprecated å»ºè­°ä½¿ç”¨ listMSDSFiles æˆ– listUsageEvidenceFiles
 */
export async function listEvidence(pageKey: string): Promise<EvidenceFile[]> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    const user = authResult.user

    let query = supabase
      .from('entry_files')
      .select(`
        *,
        energy_entries!inner(page_key, status, period_year)
      `)
      .eq('owner_id', user.id)
      .eq('energy_entries.page_key', pageKey)
      .eq('energy_entries.owner_id', user.id)
      .in('energy_entries.status', ['submitted'])
      .order('created_at', { ascending: false })

    const { data, error } = await query

    if (error) {
      console.error('Error listing evidence:', error)
      throw handleAPIError(error, 'å–å¾—æª”æ¡ˆæ¸…å–®å¤±æ•—')
    }

    // Flatten the joined data
    const flattenedData = (data || []).map(item => ({
      ...item,
      page_key: item.energy_entries?.page_key,
      status: item.energy_entries?.status,
      period_year: item.energy_entries?.period_year,
      energy_entries: undefined // Remove nested object
    }))

    return flattenedData || []
  } catch (error) {
    console.error('Error in listEvidence:', error)
    if (error instanceof Error) {
      throw error
    }
    throw new Error('å–å¾—æª”æ¡ˆæ¸…å–®æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

/**
 * å–å¾—æª”æ¡ˆçš„å…¬é–‹ URL
 */
export async function getFileUrl(filePath: string): Promise<string> {
  // åŠ å…¥è·¯å¾‘è¨ºæ–·
  console.log('ğŸ“‚ å˜—è©¦è¼‰å…¥æª”æ¡ˆ:', {
    åŸå§‹è·¯å¾‘: filePath,
    æ˜¯å¦ç‚ºç©º: !filePath,
    è·¯å¾‘é•·åº¦: filePath?.length,
    è·¯å¾‘é¡å‹: typeof filePath,
    æ˜¯å¦åŒ…å«æ–œç·š: filePath?.includes('/'),
    è·¯å¾‘é–‹é ­: filePath?.substring(0, 20),
    è·¯å¾‘çµå°¾: filePath?.substring(filePath.length - 20)
  })

  // æª¢æŸ¥è·¯å¾‘æ ¼å¼
  if (!filePath || filePath === 'null' || filePath === 'undefined') {
    console.error('âŒ æª”æ¡ˆè·¯å¾‘ç„¡æ•ˆ:', {
      filePath,
      typeOf: typeof filePath,
      isEmpty: !filePath
    })
    throw new Error('æª”æ¡ˆè·¯å¾‘ç„¡æ•ˆ')
  }

  console.log('ğŸ“‚ [getFileUrl] Attempting to get URL for:', {
    filePath,
    timestamp: new Date().toISOString()
  })

  try {
    const { data, error } = await supabase.storage
      .from('evidence')
      .createSignedUrl(filePath, 3600) // 1å°æ™‚æœ‰æ•ˆæœŸ

    if (error) {
      // âœ… æ”¹å–„éŒ¯èª¤åºåˆ—åŒ–ï¼šæå–æ‰€æœ‰å¯èƒ½çš„éŒ¯èª¤è³‡è¨Š
      const errorInfo = {
        message: error?.message || String(error),
        name: error?.name,
        status: (error as any)?.status,
        statusText: (error as any)?.statusText,
        statusCode: (error as any)?.statusCode,
        code: (error as any)?.code,
        hint: (error as any)?.hint,
        details: (error as any)?.details,
        filePath,
        // âœ… å¢åŠ æ›´è©³ç´°çš„éŒ¯èª¤ç‰©ä»¶æª¢æŸ¥
        errorKeys: Object.keys(error || {}),
        errorType: typeof error,
        errorConstructor: error?.constructor?.name,
        errorString: String(error),
        // å˜—è©¦ JSON åºåˆ—åŒ–ï¼ˆå¯èƒ½å¤±æ•—ï¼‰
        jsonAttempt: (() => {
          try {
            return JSON.stringify(error, null, 2)
          } catch {
            return '[JSON serialization failed]'
          }
        })()
      }

      console.error('âŒ [getFileUrl] Supabase storage error:', errorInfo)

      // âœ… æä¾›æ›´æœ‰ç”¨çš„éŒ¯èª¤è¨Šæ¯
      const errorMsg = error?.message || error?.name || `Storage éŒ¯èª¤ (${typeof error})`
      throw new Error(`Storage error: ${errorMsg}`)
    }

    if (!data?.signedUrl) {
      console.error('âŒ [getFileUrl] No signed URL returned:', { data, filePath })
      throw new Error('ç„¡æ³•ç”Ÿæˆæª”æ¡ˆ URL')
    }

    console.log('âœ… [getFileUrl] URL generated successfully:', {
      filePath,
      urlLength: data.signedUrl.length,
      urlPrefix: data.signedUrl.substring(0, 50)
    })

    return data.signedUrl
  } catch (error) {
    console.error('âŒ [getFileUrl] Failed to get file URL:', {
      errorMessage: (error as any)?.message || 'Unknown error',
      errorType: (error as any)?.name || typeof error,
      errorStack: (error as any)?.stack,
      errorCode: (error as any)?.code,
      errorStatus: (error as any)?.status,
      errorDetails: error,
      filePath,
      fullError: JSON.stringify(error, null, 2)
    })
    throw error instanceof Error ? error : new Error('å–å¾—æª”æ¡ˆ URL å¤±æ•—')
  }
}

/**
 * èª¿è©¦ç”¨ï¼šæª¢æŸ¥è³‡æ–™åº«ä¸­æª”æ¡ˆè·¯å¾‘çš„å®Œæ•´æ€§
 */
export async function debugFilePathsInDatabase(): Promise<void> {
  console.log('ğŸ” [Debug] Checking file paths in database...')

  try {
    // æª¢æŸ¥ entry_files è¡¨ä¸­çš„æ‰€æœ‰æª”æ¡ˆè·¯å¾‘
    const { data: allFiles, error: filesError } = await supabase
      .from('entry_files')
      .select('id, file_name, file_path, file_size, mime_type, created_at, owner_id')
      .order('created_at', { ascending: false })
      .limit(50)

    if (filesError) {
      console.error('âŒ [Debug] Failed to fetch files from database:', filesError)
      return
    }

    console.log('ğŸ“Š [Debug] Database file analysis:', {
      totalFiles: allFiles?.length || 0,
      files: allFiles?.map(f => ({
        id: f.id,
        name: f.file_name,
        path: f.file_path,
        pathAnalysis: {
          isEmpty: !f.file_path,
          length: f.file_path?.length,
          containsEvidence: f.file_path?.includes('evidence'),
          pathSegments: f.file_path?.split('/').length,
          firstSegment: f.file_path?.split('/')[0],
          lastSegment: f.file_path?.split('/').pop()
        },
        size: f.file_size,
        mimeType: f.mime_type,
        ownerId: f.owner_id?.substring(0, 8) + '...'
      }))
    })

    // åˆ†æè·¯å¾‘æ¨¡å¼
    const pathPatterns = allFiles?.map(f => f.file_path).filter(Boolean) || []
    const patternAnalysis = {
      totalPaths: pathPatterns.length,
      uniquePatterns: [...new Set(pathPatterns.map(path => {
        const parts = path.split('/')
        return parts.length > 2 ? `${parts[0]}/${parts[1]}/...` : path
      }))],
      pathStructures: pathPatterns.map(path => ({
        fullPath: path,
        segments: path.split('/').length,
        startsWithEvidence: path.startsWith('evidence/'),
        endsWithFileName: path.split('/').pop()?.includes('.')
      }))
    }

    console.log('ğŸ“ˆ [Debug] Path pattern analysis:', patternAnalysis)

    // æª¢æŸ¥ Supabase Storage ä¸­å¯¦éš›å­˜åœ¨çš„æª”æ¡ˆ
    try {
      const { data: storageFiles, error: storageError } = await supabase.storage
        .from('evidence')
        .list('', { limit: 100 })

      if (!storageError && storageFiles) {
        console.log('ğŸ’¾ [Debug] Storage bucket content:', {
          storageFiles: storageFiles.length,
          fileNames: storageFiles.map(f => f.name).slice(0, 10),
          folders: storageFiles.filter(f => !f.name.includes('.')).map(f => f.name)
        })
      } else {
        console.warn('âš ï¸ [Debug] Could not list storage files:', storageError)
      }
    } catch (storageError) {
      console.warn('âš ï¸ [Debug] Storage access failed:', storageError)
    }

  } catch (error) {
    console.error('âŒ [Debug] Database file path check failed:', error)
  }
}

/**
 * èª¿è©¦ç”¨ï¼šæª¢æŸ¥ç•¶å‰ç”¨æˆ¶æ¬Šé™å’Œèªè­‰ç‹€æ…‹
 */
export async function debugAuthAndPermissions(): Promise<void> {
  console.log('ğŸ” [Debug] Checking authentication and permissions...')

  try {
    const { data: { user }, error: authError } = await supabase.auth.getUser()

    console.log('ğŸ‘¤ [Debug] Current user info:', {
      isAuthenticated: !!user,
      userId: user?.id,
      email: user?.email,
      authError: authError?.message,
      userMetadata: user?.user_metadata,
      appMetadata: user?.app_metadata
    })

    // æª¢æŸ¥ Storage æ¬Šé™
    try {
      const { data: buckets, error: bucketsError } = await supabase.storage.listBuckets()
      console.log('ğŸª£ [Debug] Storage buckets access:', {
        canListBuckets: !bucketsError,
        bucketsCount: buckets?.length || 0,
        bucketsError: bucketsError?.message,
        buckets: buckets?.map(b => ({ name: b.name, public: b.public }))
      })
    } catch (storageError) {
      console.error('âŒ [Debug] Storage access failed:', storageError)
    }

    // æª¢æŸ¥æ˜¯å¦ç‚ºç®¡ç†å“¡
    if (user) {
      try {
        const { data: profile, error: profileError } = await supabase
          .from('profiles')
          .select('role, is_admin')
          .eq('id', user.id)
          .single()

        console.log('ğŸ‘¨â€ğŸ’¼ [Debug] User role info:', {
          hasProfile: !!profile,
          role: profile?.role,
          isAdmin: profile?.is_admin,
          profileError: profileError?.message
        })
      } catch (roleError) {
        console.error('âŒ [Debug] Role check failed:', roleError)
      }
    }

  } catch (error) {
    console.error('âŒ [Debug] Authentication check failed:', error)
  }
}

/**
 * å–å¾—æª”æ¡ˆçš„å…¬é–‹ URL - ç®¡ç†å“¡ç‰ˆæœ¬
 * ç”¨æ–¼å¯©æ ¸æ¨¡å¼ä¸‹å­˜å–å…¶ä»–ç”¨æˆ¶çš„æª”æ¡ˆ
 */
export async function getFileUrlForAdmin(
  filePath: string,
  ownerId?: string,
  isReviewMode: boolean = false
): Promise<string> {
  // ç®¡ç†å“¡æ¨¡å¼è·¯å¾‘è¨ºæ–·
  console.log('ğŸ” ç®¡ç†å“¡æ¨¡å¼æª”æ¡ˆè·¯å¾‘è¨ºæ–·:', {
    åŸå§‹è·¯å¾‘: filePath,
    æª”æ¡ˆæ“æœ‰è€…: ownerId,
    å¯©æ ¸æ¨¡å¼: isReviewMode,
    è·¯å¾‘åˆ†æ: {
      æ˜¯å¦ç‚ºç©º: !filePath,
      è·¯å¾‘é•·åº¦: filePath?.length,
      åŒ…å«evidence: filePath?.includes('evidence'),
      è·¯å¾‘çµæ§‹: filePath?.split('/'),
      é–‹é ­30å­—å…ƒ: filePath?.substring(0, 30),
      çµå°¾30å­—å…ƒ: filePath?.substring(filePath.length - 30)
    }
  })

  // æª¢æŸ¥è·¯å¾‘æœ‰æ•ˆæ€§
  if (!filePath || filePath === 'null' || filePath === 'undefined') {
    console.error('âŒ [getFileUrlForAdmin] ç®¡ç†å“¡æ¨¡å¼æª”æ¡ˆè·¯å¾‘ç„¡æ•ˆ:', {
      filePath,
      ownerId,
      å•é¡Œ: 'è·¯å¾‘ç‚ºç©ºæˆ–ç„¡æ•ˆ'
    })
    throw new Error('ç®¡ç†å“¡æ¨¡å¼ï¼šæª”æ¡ˆè·¯å¾‘ç„¡æ•ˆ')
  }

  console.log('ğŸ” [getFileUrlForAdmin] Admin file access request:', {
    filePath,
    ownerId,
    isReviewMode,
    timestamp: new Date().toISOString()
  })

  try {
    // é¦–å…ˆå˜—è©¦æ¨™æº–æ–¹å¼
    console.log('ğŸ“ [getFileUrlForAdmin] Trying standard approach first...')
    const { data, error } = await supabase.storage
      .from('evidence')
      .createSignedUrl(filePath, 60) // 60ç§’æœ‰æ•ˆæœŸï¼ˆå®‰å…¨è€ƒé‡ï¼‰

    if (!error && data?.signedUrl) {
      console.log('âœ… [getFileUrlForAdmin] Standard approach succeeded')
      return data.signedUrl
    }

    // å¦‚æœæ¨™æº–æ–¹å¼å¤±æ•—ï¼Œè¨˜éŒ„éŒ¯èª¤
    if (error) {
      console.error('âš ï¸ [getFileUrlForAdmin] Standard approach failed:', {
        message: error?.message,
        status: (error as any)?.status,
        statusText: (error as any)?.statusText,
        error: (error as any)?.error,
        code: (error as any)?.code,
        hint: (error as any)?.hint,
        details: (error as any)?.details,
        filePath,
        ownerId,
        fullError: JSON.stringify(error, null, 2)
      })
    }

    // å˜—è©¦ä½¿ç”¨å…¬é–‹ URLï¼ˆå¦‚æœ bucket è¨­ç½®ç‚ºå…¬é–‹ï¼‰
    console.log('ğŸ“ [getFileUrlForAdmin] Trying public URL approach...')
    const { data: publicUrlData } = supabase.storage
      .from('evidence')
      .getPublicUrl(filePath)

    if (publicUrlData?.publicUrl) {
      console.log('âœ… [getFileUrlForAdmin] Public URL generated:', {
        url: publicUrlData.publicUrl.substring(0, 50) + '...'
      })
      // ç›´æ¥è¿”å›å…¬é–‹ URLï¼Œè®“ç€è¦½å™¨å˜—è©¦è¼‰å…¥
      // å¦‚æœ bucket æ˜¯å…¬é–‹çš„ï¼Œé€™æ‡‰è©²å¯ä»¥å·¥ä½œ
      return publicUrlData.publicUrl
    }

    // å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—ï¼Œæ‹‹å‡ºéŒ¯èª¤
    const errorMessage = isReviewMode
      ? `å¯©æ ¸æ¨¡å¼ï¼šç„¡æ³•å­˜å–ç”¨æˆ¶ ${ownerId} çš„æª”æ¡ˆ ${filePath}`
      : `ç®¡ç†å“¡æ¬Šé™ä¸è¶³ï¼šç„¡æ³•å­˜å–æª”æ¡ˆ ${filePath}`

    console.error('âŒ [getFileUrlForAdmin] All approaches failed')
    throw new Error(errorMessage)

  } catch (error) {
    console.error('âŒ [getFileUrlForAdmin] Admin file URL generation failed:', {
      errorMessage: (error as any)?.message || 'Unknown error',
      errorType: (error as any)?.name || typeof error,
      errorStack: (error as any)?.stack,
      errorCode: (error as any)?.code,
      errorStatus: (error as any)?.status,
      errorDetails: error,
      filePath,
      ownerId,
      isReviewMode,
      fullError: JSON.stringify(error, null, 2)
    })
    throw error
  }
}

/**
 * åˆªé™¤è­‰æ“šæª”æ¡ˆ
 */
export async function deleteEvidence(fileId: string): Promise<void> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    const user = authResult.user

    console.log('ğŸ—‘ï¸ [deleteEvidence] Starting deletion:', { fileId, userId: user.id })

    // 1. å…ˆå–å¾—æª”æ¡ˆè³‡è¨Š
    const { data: fileData, error: fetchError } = await supabase
      .from('entry_files')
      .select('file_path, owner_id')
      .eq('id', fileId)
      // âœ… ç§»é™¤ owner_id æª¢æŸ¥ï¼Œæ”¹ç”± RLS Policy æ§åˆ¶æ¬Šé™
      // RLS Policy å…è¨±åˆªé™¤ï¼š(1) ç®¡ç†å“¡çš„ä»»ä½•æª”æ¡ˆ (2) è‡ªå·± entry ä¸‹çš„ä»»ä½•æª”æ¡ˆ
      .maybeSingle()  // âœ… ä½¿ç”¨ maybeSingle() å…è¨± 0 æˆ– 1 ç­†çµæœ

    if (fetchError) {
      console.error('âŒ [deleteEvidence] Error fetching file data:', fetchError)
      throw handleAPIError(fetchError, 'å–å¾—æª”æ¡ˆè³‡è¨Šå¤±æ•—')
    }

    if (!fileData) {
      console.warn(`âš ï¸ [deleteEvidence] File ${fileId} not found or already deleted`)
      return  // éœé»˜è¿”å›ï¼Œè¦–ç‚ºæª”æ¡ˆå·²è¢«åˆªé™¤
    }

    console.log('ğŸ“‚ [deleteEvidence] File info retrieved:', {
      filePath: fileData.file_path,
      ownerId: fileData.owner_id
    })

    // 2. âœ… å…ˆå¾ Storage åˆªé™¤å¯¦é«”æª”æ¡ˆï¼ˆLinus ä¿®æ­£ï¼šå…ˆåˆªå¯¦é«”è³‡æºï¼Œå†åˆªç´¢å¼•ï¼‰
    try {
      console.log('ğŸ—‘ï¸ [deleteEvidence] Deleting from Storage...')
      const { error: storageError } = await supabase.storage
        .from('evidence')
        .remove([fileData.file_path])

      if (storageError) {
        console.warn('âš ï¸ [deleteEvidence] Storage deletion failed (will continue):', {
          error: storageError,
          message: storageError.message,
          filePath: fileData.file_path
        })
        // âœ… Storage éŒ¯èª¤ä¸æ‹‹å‡ºç•°å¸¸ - æª”æ¡ˆå¯èƒ½å·²ä¸å­˜åœ¨ï¼Œç¹¼çºŒæ¸…ç†è³‡æ–™åº«
      } else {
        console.log('âœ… [deleteEvidence] Storage file deleted successfully')
      }
    } catch (storageError) {
      console.warn('âš ï¸ [deleteEvidence] Storage deletion exception (will continue):', storageError)
      // âœ… Storage ç•°å¸¸ä¸æ‡‰é˜»æ­¢è³‡æ–™åº«æ¸…ç†
    }

    // 3. âœ… å†å¾è³‡æ–™åº«åˆªé™¤è¨˜éŒ„ï¼ˆç„¡è«– Storage æ˜¯å¦æˆåŠŸï¼‰
    console.log('ğŸ—‘ï¸ [deleteEvidence] Deleting database record...')
    const { error: dbError } = await supabase
      .from('entry_files')
      .delete()
      .eq('id', fileId)
      // âœ… ç§»é™¤ owner_id æª¢æŸ¥ï¼Œæ”¹ç”± RLS Policy æ§åˆ¶æ¬Šé™

    if (dbError) {
      console.error('âŒ [deleteEvidence] Database deletion failed:', dbError)
      throw handleAPIError(dbError, 'åˆªé™¤æª”æ¡ˆè¨˜éŒ„å¤±æ•—')
    }

    console.log('âœ… [deleteEvidence] File deleted successfully:', fileId)
  } catch (error) {
    console.error('âŒ [deleteEvidence] Error:', error)
    if (error instanceof Error) {
      throw error
    }
    throw new Error('åˆªé™¤æª”æ¡ˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

/**
 * ç®¡ç†å“¡åˆªé™¤è­‰æ“šæª”æ¡ˆï¼ˆä¸æª¢æŸ¥ owner_idï¼Œéœ€è¦ç®¡ç†å“¡æ¬Šé™ï¼‰
 *
 * ç”¨é€”ï¼šç®¡ç†å“¡åœ¨å¯©æ ¸æ¨¡å¼ä¸‹åˆªé™¤ç”¨æˆ¶ä¸Šå‚³çš„æª”æ¡ˆ
 *
 * @param fileId - è¦åˆªé™¤çš„æª”æ¡ˆ ID
 * @throws å¦‚æœéç®¡ç†å“¡å‘¼å«ï¼Œæ‹‹å‡ºæ¬Šé™éŒ¯èª¤
 */
export async function adminDeleteEvidence(fileId: string): Promise<void> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    const user = authResult.user

    console.log('ğŸ” [adminDeleteEvidence] Starting admin deletion:', { fileId, adminId: user.id })

    // 1. é©—è­‰ç®¡ç†å“¡æ¬Šé™
    const { data: profile, error: profileError } = await supabase
      .from('profiles')
      .select('role')
      .eq('id', user.id)
      .single()

    if (profileError || profile?.role !== 'admin') {
      console.error('âŒ [adminDeleteEvidence] Permission denied:', { userId: user.id, role: profile?.role })
      throw new Error('æ¬Šé™ä¸è¶³ï¼šåƒ…ç®¡ç†å“¡å¯åŸ·è¡Œæ­¤æ“ä½œ')
    }

    console.log('âœ… [adminDeleteEvidence] Admin permission verified')

    // 2. æŸ¥è©¢æª”æ¡ˆè³‡è¨Šï¼ˆä¸éæ¿¾ owner_idï¼‰
    const { data: fileData, error: fetchError } = await supabase
      .from('entry_files')
      .select('file_path, owner_id')
      .eq('id', fileId)
      .maybeSingle()

    if (fetchError) {
      console.error('âŒ [adminDeleteEvidence] Error fetching file:', fetchError)
      throw handleAPIError(fetchError, 'å–å¾—æª”æ¡ˆè³‡è¨Šå¤±æ•—')
    }

    if (!fileData) {
      console.warn(`âš ï¸ [adminDeleteEvidence] File ${fileId} not found or already deleted`)
      return  // éœé»˜è¿”å›ï¼Œè¦–ç‚ºæª”æ¡ˆå·²è¢«åˆªé™¤
    }

    console.log('ğŸ“‚ [adminDeleteEvidence] File info retrieved:', {
      filePath: fileData.file_path,
      ownerId: fileData.owner_id
    })

    // 3. å¾ Storage åˆªé™¤å¯¦é«”æª”æ¡ˆ
    try {
      console.log('ğŸ—‘ï¸ [adminDeleteEvidence] Deleting from Storage...')
      const { error: storageError } = await supabase.storage
        .from('evidence')
        .remove([fileData.file_path])

      if (storageError) {
        console.warn('âš ï¸ [adminDeleteEvidence] Storage deletion failed (will continue):', storageError)
        // Storage éŒ¯èª¤ä¸æ‹‹å‡º - æª”æ¡ˆå¯èƒ½å·²ä¸å­˜åœ¨ï¼Œç¹¼çºŒæ¸…ç†è³‡æ–™åº«
      } else {
        console.log('âœ… [adminDeleteEvidence] Storage file deleted')
      }
    } catch (storageError) {
      console.warn('âš ï¸ [adminDeleteEvidence] Storage exception (will continue):', storageError)
    }

    // 4. å¾è³‡æ–™åº«åˆªé™¤è¨˜éŒ„ï¼ˆä¸éæ¿¾ owner_idï¼‰
    console.log('ğŸ—‘ï¸ [adminDeleteEvidence] Deleting database record...')
    const { error: dbError } = await supabase
      .from('entry_files')
      .delete()
      .eq('id', fileId)
      // â­ ä¸æª¢æŸ¥ owner_idï¼Œå…è¨±ç®¡ç†å“¡åˆªé™¤ä»»ä½•æª”æ¡ˆ

    if (dbError) {
      console.error('âŒ [adminDeleteEvidence] Database deletion failed:', dbError)
      throw handleAPIError(dbError, 'åˆªé™¤æª”æ¡ˆè¨˜éŒ„å¤±æ•—')
    }

    console.log('âœ… [adminDeleteEvidence] Admin deletion completed:', fileId)
  } catch (error) {
    console.error('âŒ [adminDeleteEvidence] Error:', error)
    if (error instanceof Error) {
      throw error
    }
    throw new Error('ç®¡ç†å“¡åˆªé™¤æª”æ¡ˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}
/**
 * å°‡è‰ç¨¿æª”æ¡ˆæäº¤ï¼ˆç‹€æ…‹æ”¹ç‚º submittedï¼‰
 */
export async function commitEvidence(params: { entryId?: string; pageKey: string }): Promise<void> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    const user = authResult.user

    console.log('Committing evidence for:', {
      user_id: user.id,
      pageKey: params.pageKey,
    })

    // First, get all file IDs that match the criteria via JOIN
    // æŸ¥æ‰¾ draft å’Œ submitted ç‹€æ…‹çš„è¨˜éŒ„ï¼Œå› ç‚ºæäº¤å¾Œç‹€æ…‹æœƒè®Šç‚º submitted
    const { data: filesData, error: fetchError } = await supabase
      .from('entry_files')
      .select(`
        id,
        energy_entries!inner(page_key, owner_id, status)
      `)
      .eq('owner_id', user.id)
      .eq('energy_entries.page_key', params.pageKey)
      .eq('energy_entries.owner_id', user.id)
      .in('energy_entries.status', ['submitted'])
      

    console.log('Files to commit:', {
      count: filesData?.length || 0,
      files: filesData,
      error: fetchError
    })

    if (fetchError) {
    }

    if (!filesData || filesData.length === 0) {
      return // No files to commit
    }

    const fileIds = filesData.map(f => f.id)
    const updateData: any = {}

    if (params.entryId) {
      updateData.entry_id = params.entryId
      
      // æ›´æ–°æ‰€æœ‰é—œè¯çš„æª”æ¡ˆ
      const { error } = await supabase
        .from('entry_files')
        .update(updateData)
        .in('id', fileIds)
        .eq('owner_id', user.id)
      
      if (error) {
        console.error('Error updating file entry_id:', error)
        throw handleAPIError(error, 'æ›´æ–°æª”æ¡ˆé—œè¯å¤±æ•—')
      }
    }
    
    // ä¸å†åœ¨é€™è£¡åŸ·è¡Œç©ºçš„ updateï¼Œå› ç‚ºæˆ‘å€‘å·²ç¶“è™•ç†äº† entry_id çš„æ›´æ–°

    // å·²åœ¨ä¸Šé¢è™•ç†äº†éŒ¯èª¤
  } catch (error) {
    console.error('Error in commitEvidence:', error)
    if (error instanceof Error) {
      throw error
    }
    throw new Error('æäº¤æª”æ¡ˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

/**
 * å–å¾—æ‰€æœ‰æª”æ¡ˆæ¸…å–®ï¼ˆåŒ…å«å·²æäº¤çš„ï¼‰
 */
export async function listAllEvidence(pageKey: string): Promise<EvidenceFile[]> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    const user = authResult.user

    const { data, error } = await supabase
      .from('entry_files')
      .select(`
        *,
        energy_entries!inner(page_key, status, period_year)
      `)
      .eq('owner_id', user.id)
      .eq('energy_entries.page_key', pageKey)
      .eq('energy_entries.owner_id', user.id)
      .order('created_at', { ascending: false })

    if (error) {
      console.error('Error listing all evidence:', error)
      throw handleAPIError(error, 'å–å¾—æª”æ¡ˆæ¸…å–®å¤±æ•—')
    }

    // Flatten the joined data
    const flattenedData = (data || []).map(item => ({
      ...item,
      page_key: item.energy_entries?.page_key,
      status: item.energy_entries?.status,
      period_year: item.energy_entries?.period_year,
      energy_entries: undefined // Remove nested object
    }))

    return flattenedData || []
  } catch (error) {
    console.error('Error in listAllEvidence:', error)
    if (error instanceof Error) {
      throw error
    }
    throw new Error('å–å¾—æª”æ¡ˆæ¸…å–®æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

/**
 * æª¢æŸ¥æª”æ¡ˆå¤§å°å’Œé¡å‹
 */
export function validateFile(file: File, options?: {
  maxSize?: number
  allowedTypes?: string[]
}): { valid: boolean; error?: string } {
  const maxSize = options?.maxSize || 10 * 1024 * 1024 // é è¨­ 10MB

  // å¦‚æœæœ‰æŒ‡å®š allowedTypes æ‰é€²è¡Œæª¢æŸ¥ï¼Œå¦å‰‡å…è¨±æ‰€æœ‰é¡å‹
  const allowedTypes = options?.allowedTypes

  if (file.size > maxSize) {
    return {
      valid: false,
      error: `æª”æ¡ˆå¤§å°ä¸èƒ½è¶…é ${Math.round(maxSize / 1024 / 1024)}MB`
    }
  }

  if (allowedTypes && !allowedTypes.includes(file.type)) {
    return {
      valid: false,
      error: 'ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼'
    }
  }

  return { valid: true }
}

// ç‚ºäº†å‘å¾Œç›¸å®¹ï¼Œæ–°å¢åˆ¥å
export const uploadEvidenceSimple = uploadEvidence
export const deleteEvidenceFile = deleteEvidence

// æ–°å¢ç¼ºå¤±çš„å‡½æ•¸
export async function getEntryFiles(entryId: string): Promise<EvidenceFile[]> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }

    const { data, error } = await supabase
      .from('entry_files')
      .select('*')
      .eq('entry_id', entryId)
      .order('created_at', { ascending: false })

    if (error) {
      throw handleAPIError(error, 'å–å¾—æª”æ¡ˆå¤±æ•—')
    }

    console.log('ğŸ“ [getEntryFiles] Raw data from database:', {
      entryId,
      count: data?.length || 0,
      files: data?.map(f => ({
        id: f.id,
        name: f.file_name,
        month: f.month,
        page_key: f.page_key,
        has_month: f.month !== undefined,
        has_page_key: f.page_key !== undefined
      })) || []
    })

    return data || []
  } catch (error) {
    console.error('âŒ [getEntryFiles] Error:', error)
    if (error instanceof Error) {
      throw error
    }
    throw new Error('å–å¾—æª”æ¡ˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

export async function updateFileEntryAssociation(fileId: string, entryId: string): Promise<void> {
  try {
    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }
    
    const { error } = await supabase
      .from('entry_files')
      .update({ entry_id: entryId })
      .eq('id', fileId)
      .eq('owner_id', authResult.user.id)
    
    if (error) {
      throw handleAPIError(error, 'æ›´æ–°æª”æ¡ˆé—œè¯å¤±æ•—')
    }
  } catch (error) {
    if (error instanceof Error) {
      throw error
    }
    throw new Error('æ›´æ–°æª”æ¡ˆé—œè¯æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

// å°å‡ºå…§éƒ¨å‡½æ•¸ä¾›å…ƒä»¶ä½¿ç”¨
export { getCategoryFromPageKey }

// Add missing function for WD40Page
export async function debugDatabaseContent(): Promise<void> {
  console.log('Debug database content called')
}

/**
 * æ¸…ç†å­¤å…’æª”æ¡ˆè¨˜éŒ„
 * åˆªé™¤æ‰€æœ‰æ²’æœ‰å°æ‡‰ energy_entries çš„ entry_files è¨˜éŒ„
 *
 * ä½¿ç”¨å ´æ™¯:
 * - ç®¡ç†å“¡å·¥å…·
 * - å®šæœŸç¶­è­·ä»»å‹™
 * - è§£æ±ºã€Œå¹½éˆæª”æ¡ˆã€å•é¡Œ
 *
 * @returns Promise<{ deletedCount: number, errors: string[] }>
 */
export async function cleanOrphanFiles(): Promise<{ deletedCount: number, errors: string[] }> {
  try {
    console.group('ğŸ§¹ [cleanOrphanFiles] Starting orphan file cleanup')

    const authResult = await validateAuth()
    if (authResult.error || !authResult.user) {
      throw authResult.error || new Error('ä½¿ç”¨è€…æœªç™»å…¥')
    }

    // 1. æŸ¥è©¢æ‰€æœ‰ç•¶å‰ç”¨æˆ¶çš„æª”æ¡ˆè¨˜éŒ„
    const { data: allFiles, error: queryError } = await supabase
      .from('entry_files')
      .select('id, file_path, entry_id, created_at')
      .eq('owner_id', authResult.user.id)

    if (queryError) {
      console.error('âŒ [cleanOrphanFiles] Query error:', queryError)
      throw handleAPIError(queryError, 'æŸ¥è©¢æª”æ¡ˆè¨˜éŒ„å¤±æ•—')
    }

    if (!allFiles || allFiles.length === 0) {
      console.log('â„¹ï¸ [cleanOrphanFiles] No files found')
      console.groupEnd()
      return { deletedCount: 0, errors: [] }
    }

    console.log(`ğŸ“Š [cleanOrphanFiles] Found ${allFiles.length} file records, checking for orphans...`)

    // 2. å°æ¯å€‹æª”æ¡ˆï¼Œæª¢æŸ¥å…¶ entry_id æ˜¯å¦å°æ‡‰æœ‰æ•ˆçš„ energy_entries
    const orphanFiles: typeof allFiles = []

    for (const file of allFiles) {
      const { data: entry } = await supabase
        .from('energy_entries')
        .select('id')
        .eq('id', file.entry_id)
        .maybeSingle()

      if (!entry) {
        console.log(`ğŸ” [cleanOrphanFiles] Found orphan file:`, {
          fileId: file.id,
          entryId: file.entry_id,
          filePath: file.file_path
        })
        orphanFiles.push(file)
      }
    }

    console.log(`ğŸ¯ [cleanOrphanFiles] Found ${orphanFiles.length} orphan files`)

    if (orphanFiles.length === 0) {
      console.groupEnd()
      return { deletedCount: 0, errors: [] }
    }

    // 3. åˆªé™¤å­¤å…’æª”æ¡ˆ
    let deletedCount = 0
    const errors: string[] = []

    for (const orphan of orphanFiles) {
      try {
        // å…ˆåˆª Storage
        try {
          await supabase.storage
            .from('evidence')
            .remove([orphan.file_path])
          console.log(`âœ… [cleanOrphanFiles] Deleted storage file: ${orphan.file_path}`)
        } catch (storageError) {
          console.warn(`âš ï¸ [cleanOrphanFiles] Storage deletion failed (continuing):`, storageError)
        }

        // å†åˆªè³‡æ–™åº«
        const { error: dbError } = await supabase
          .from('entry_files')
          .delete()
          .eq('id', orphan.id)

        if (dbError) {
          errors.push(`Failed to delete file ${orphan.id}: ${dbError.message}`)
          console.error(`âŒ [cleanOrphanFiles] DB deletion failed:`, dbError)
        } else {
          deletedCount++
          console.log(`âœ… [cleanOrphanFiles] Deleted orphan file: ${orphan.id}`)
        }
      } catch (error) {
        const errorMsg = error instanceof Error ? error.message : String(error)
        errors.push(`Error processing file ${orphan.id}: ${errorMsg}`)
        console.error(`âŒ [cleanOrphanFiles] Error:`, error)
      }
    }

    console.log(`âœ… [cleanOrphanFiles] Cleanup complete:`, {
      totalOrphans: orphanFiles.length,
      deletedCount,
      errorCount: errors.length
    })
    console.groupEnd()

    return { deletedCount, errors }
  } catch (error) {
    console.error('âŒ [cleanOrphanFiles] Fatal error:', error)
    console.groupEnd()
    throw error instanceof Error ? error : new Error('æ¸…ç†å­¤å…’æª”æ¡ˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤')
  }
}

/**
 * æ‰¹æ¬¡ä¸Šå‚³å¤šå€‹æª”æ¡ˆ
 * @param files æª”æ¡ˆé™£åˆ—
 * @param metadataArray å°æ‡‰çš„ä¸­ç¹¼è³‡æ–™é™£åˆ—
 * @param onProgress é€²åº¦å›èª¿å‡½æ•¸
 * @returns ä¸Šå‚³çµæœé™£åˆ—
 */
export async function batchUploadEvidence(
  files: File[],
  metadataArray: (FileMetadata & { entryId?: string; allowOverwrite?: boolean })[],
  onProgress?: (completed: number, total: number, currentFile: string) => void
): Promise<{ successes: EvidenceFile[], failures: { file: File, error: string }[] }> {
  if (files.length !== metadataArray.length) {
    throw new Error('æª”æ¡ˆæ•¸é‡èˆ‡ä¸­ç¹¼è³‡æ–™æ•¸é‡ä¸ç¬¦')
  }

  const successes: EvidenceFile[] = []
  const failures: { file: File, error: string }[] = []
  let completed = 0

  console.log('ğŸš€ [batchUploadEvidence] Starting batch upload:', {
    totalFiles: files.length,
    files: files.map(f => f.name)
  })

  // é€ä¸€ä¸Šå‚³æª”æ¡ˆï¼ˆé¿å…ä¸¦ç™¼å°è‡´çš„è³‡æ–™åº«å£“åŠ›ï¼‰
  for (let i = 0; i < files.length; i++) {
    const file = files[i]
    const metadata = metadataArray[i]

    try {
      onProgress?.(completed, files.length, file.name)

      console.log(`ğŸ“¤ [batchUploadEvidence] Uploading file ${i + 1}/${files.length}:`, {
        fileName: file.name,
        fileSize: file.size,
        category: metadata.category,
        month: metadata.month
      })

      const result = await uploadEvidence(file, metadata)
      successes.push(result)

      completed++
      console.log(`âœ… [batchUploadEvidence] File uploaded successfully:`, {
        fileName: file.name,
        fileId: result.id,
        completed: completed,
        remaining: files.length - completed
      })

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'ä¸Šå‚³å¤±æ•—'
      failures.push({ file, error: errorMessage })

      console.error(`âŒ [batchUploadEvidence] File upload failed:`, {
        fileName: file.name,
        error: errorMessage
      })
    }

    // é€šçŸ¥é€²åº¦æ›´æ–°
    onProgress?.(completed, files.length, completed < files.length ? files[completed]?.name || '' : '')
  }

  console.log('ğŸ [batchUploadEvidence] Batch upload completed:', {
    totalFiles: files.length,
    successes: successes.length,
    failures: failures.length,
    successFiles: successes.map(s => s.file_name),
    failureFiles: failures.map(f => f.file.name)
  })

  return { successes, failures }
}
